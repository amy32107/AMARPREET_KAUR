{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name:- Amarpreet kaur lotte\n",
    "\n",
    "\n",
    "Email:- amarpreetkaurlotte@gmail.com\n",
    "\n",
    "\n",
    "Codsoft_List_Task5:- CREDIT CARD FRAUD DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    ")\n",
    "from imblearn.under_sampling import RandomUnderSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preview:\n",
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('creditcard.csv')\n",
    "# Display the first few rows\n",
    "print(\"Dataset preview:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1:- Preprocessing Drop 'Time' column and separate features and target\n",
    "X = data.drop(columns=['Time', 'Class'])\n",
    "y = data['Class']\n",
    "\n",
    "# Normalize the 'Amount' feature\n",
    "scaler = StandardScaler()\n",
    "X['Amount'] = scaler.fit_transform(X[['Amount']])\n",
    "\n",
    "# Address class imbalance using undersampling\n",
    "fraudulent = data[data['Class'] == 1]\n",
    "genuine = data[data['Class'] == 0].sample(n=len(fraudulent), random_state=42)\n",
    "balanced_data = pd.concat([fraudulent, genuine])\n",
    "\n",
    "X_balanced = balanced_data.drop(columns=['Time', 'Class'])\n",
    "y_balanced = balanced_data['Class']\n",
    "X_balanced['Amount'] = scaler.fit_transform(X_balanced[['Amount']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2:- Train-test split\n",
    "X_train_balanced, X_test_balanced, y_train_balanced, y_test_balanced = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3:-\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred_rf = rf_model.predict(X_test_balanced)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred_lr = lr_model.predict(X_test_balanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4:-\n",
    "#  Evaluate Random Forest\n",
    "rf_precision = precision_score(y_test_balanced, y_pred_rf)\n",
    "rf_recall = recall_score(y_test_balanced, y_pred_rf)\n",
    "rf_f1 = f1_score(y_test_balanced, y_pred_rf)\n",
    "rf_auc = roc_auc_score(y_test_balanced, rf_model.predict_proba(X_test_balanced)[:, 1])\n",
    "rf_accuracy = accuracy_score(y_test_balanced, y_pred_rf)\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "lr_precision = precision_score(y_test_balanced, y_pred_lr)\n",
    "lr_recall = recall_score(y_test_balanced, y_pred_lr)\n",
    "lr_f1 = f1_score(y_test_balanced, y_pred_lr)\n",
    "lr_auc = roc_auc_score(y_test_balanced, lr_model.predict_proba(X_test_balanced)[:, 1])\n",
    "lr_accuracy = accuracy_score(y_test_balanced, y_pred_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Logistic Regression': {'Accuracy': 0.949238578680203,\n",
      "                         'F1-Score': 0.9489795918367347,\n",
      "                         'Precision': 0.9489795918367347,\n",
      "                         'ROC-AUC': 0.981962481962482,\n",
      "                         'Recall': 0.9489795918367347},\n",
      " 'Random Forest': {'Accuracy': 0.949238578680203,\n",
      "                   'F1-Score': 0.9484536082474228,\n",
      "                   'Precision': 0.9583333333333334,\n",
      "                   'ROC-AUC': 0.9880952380952381,\n",
      "                   'Recall': 0.9387755102040817}}\n"
     ]
    }
   ],
   "source": [
    "# Step 5:-\n",
    "#  Display results\n",
    "evaluation_results = {\n",
    "    \"Random Forest\": {\n",
    "        \"Precision\": rf_precision,\n",
    "        \"Recall\": rf_recall,\n",
    "        \"F1-Score\": rf_f1,\n",
    "        \"ROC-AUC\": rf_auc,\n",
    "        \"Accuracy\": rf_accuracy,\n",
    "    },\n",
    "    \"Logistic Regression\": {\n",
    "        \"Precision\": lr_precision,\n",
    "        \"Recall\": lr_recall,\n",
    "        \"F1-Score\": lr_f1,\n",
    "        \"ROC-AUC\": lr_auc,\n",
    "        \"Accuracy\": lr_accuracy,\n",
    "    },\n",
    "}\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(evaluation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter an index from the test dataset (valid range: 0 to 196)\n",
      "{'Actual Class': 1, 'Random Forest Prediction': 1, 'Logistic Regression Prediction': 1}\n"
     ]
    }
   ],
   "source": [
    "# Function to predict and compare results\n",
    "def predict_and_compare():\n",
    "    try:\n",
    "        # Inform user about valid index range\n",
    "        print(f\"Enter an index from the test dataset (valid range: 0 to {len(X_test_balanced) - 1})\")\n",
    "\n",
    "        # User input for index\n",
    "        index = int(input(\"Enter the index: \"))\n",
    "\n",
    "        # Ensure the index is valid\n",
    "        if index < 0 or index >= len(X_test_balanced):\n",
    "            return f\"Error: Index must be between 0 and {len(X_test_balanced) - 1}.\"\n",
    "\n",
    "        # Fetch input features and actual class\n",
    "        input_features = X_test_balanced.iloc[[index]]  # Keep as DataFrame\n",
    "        actual_class = y_test_balanced.iloc[index]\n",
    "\n",
    "        # Predictions from both models\n",
    "        rf_prediction = rf_model.predict(input_features)[0]\n",
    "        lr_prediction = lr_model.predict(input_features)[0]\n",
    "\n",
    "        # Display results\n",
    "        result = {\n",
    "            \"Actual Class\": actual_class,\n",
    "            \"Random Forest Prediction\": rf_prediction,\n",
    "            \"Logistic Regression Prediction\": lr_prediction,\n",
    "        }\n",
    "        return result\n",
    "    except ValueError:\n",
    "        return \"Error: Please enter a valid integer index.\"\n",
    "\n",
    "# Call the function to get predictions and comparison\n",
    "result = predict_and_compare()\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
