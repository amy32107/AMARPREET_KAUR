{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69548164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2867bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for device\n",
    "device=torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "290a408d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "952e0046",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms\n",
    "transformer=transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
    "                        [0.5,0.5,0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e5453b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ImageFolder in module torchvision.datasets.folder:\n",
      "\n",
      "class ImageFolder(DatasetFolder)\n",
      " |  ImageFolder(root: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, loader: Callable[[str], Any] = <function default_loader at 0x00000232BFC4EAC0>, is_valid_file: Optional[Callable[[str], bool]] = None)\n",
      " |  \n",
      " |  A generic data loader where the images are arranged in this way by default: ::\n",
      " |  \n",
      " |      root/dog/xxx.png\n",
      " |      root/dog/xxy.png\n",
      " |      root/dog/[...]/xxz.png\n",
      " |  \n",
      " |      root/cat/123.png\n",
      " |      root/cat/nsdf3.png\n",
      " |      root/cat/[...]/asd932_.png\n",
      " |  \n",
      " |  This class inherits from :class:`~torchvision.datasets.DatasetFolder` so\n",
      " |  the same methods can be overridden to customize the dataset.\n",
      " |  \n",
      " |  Args:\n",
      " |      root (string): Root directory path.\n",
      " |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      " |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      " |      target_transform (callable, optional): A function/transform that takes in the\n",
      " |          target and transforms it.\n",
      " |      loader (callable, optional): A function to load an image given its path.\n",
      " |      is_valid_file (callable, optional): A function that takes path of an Image file\n",
      " |          and check if the file is a valid file (used to check of corrupt files)\n",
      " |  \n",
      " |   Attributes:\n",
      " |      classes (list): List of the class names sorted alphabetically.\n",
      " |      class_to_idx (dict): Dict with items (class_name, class_index).\n",
      " |      imgs (list): List of (image path, class_index) tuples\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ImageFolder\n",
      " |      DatasetFolder\n",
      " |      torchvision.datasets.vision.VisionDataset\n",
      " |      torch.utils.data.dataset.Dataset\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, root: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, loader: Callable[[str], Any] = <function default_loader at 0x00000232BFC4EAC0>, is_valid_file: Optional[Callable[[str], bool]] = None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  __parameters__ = ()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from DatasetFolder:\n",
      " |  \n",
      " |  __getitem__(self, index: int) -> Tuple[Any, Any]\n",
      " |      Args:\n",
      " |          index (int): Index\n",
      " |      \n",
      " |      Returns:\n",
      " |          tuple: (sample, target) where target is class_index of the target class.\n",
      " |  \n",
      " |  __len__(self) -> int\n",
      " |  \n",
      " |  find_classes(self, directory: str) -> Tuple[List[str], Dict[str, int]]\n",
      " |      Find the class folders in a dataset structured as follows::\n",
      " |      \n",
      " |          directory/\n",
      " |          ├── class_x\n",
      " |          │   ├── xxx.ext\n",
      " |          │   ├── xxy.ext\n",
      " |          │   └── ...\n",
      " |          │       └── xxz.ext\n",
      " |          └── class_y\n",
      " |              ├── 123.ext\n",
      " |              ├── nsdf3.ext\n",
      " |              └── ...\n",
      " |              └── asd932_.ext\n",
      " |      \n",
      " |      This method can be overridden to only consider\n",
      " |      a subset of classes, or to adapt to a different dataset directory structure.\n",
      " |      \n",
      " |      Args:\n",
      " |          directory(str): Root directory path, corresponding to ``self.root``\n",
      " |      \n",
      " |      Raises:\n",
      " |          FileNotFoundError: If ``dir`` has no class folders.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from DatasetFolder:\n",
      " |  \n",
      " |  make_dataset(directory: str, class_to_idx: Dict[str, int], extensions: Optional[Tuple[str, ...]] = None, is_valid_file: Optional[Callable[[str], bool]] = None) -> List[Tuple[str, int]]\n",
      " |      Generates a list of samples of a form (path_to_sample, class).\n",
      " |      \n",
      " |      This can be overridden to e.g. read files from a compressed zip file instead of from the disk.\n",
      " |      \n",
      " |      Args:\n",
      " |          directory (str): root dataset directory, corresponding to ``self.root``.\n",
      " |          class_to_idx (Dict[str, int]): Dictionary mapping class name to class index.\n",
      " |          extensions (optional): A list of allowed extensions.\n",
      " |              Either extensions or is_valid_file should be passed. Defaults to None.\n",
      " |          is_valid_file (optional): A function that takes path of a file\n",
      " |              and checks if the file is a valid file\n",
      " |              (used to check of corrupt files) both extensions and\n",
      " |              is_valid_file should not be passed. Defaults to None.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case ``class_to_idx`` is empty.\n",
      " |          ValueError: In case ``extensions`` and ``is_valid_file`` are None or both are not None.\n",
      " |          FileNotFoundError: In case no valid file was found for any class.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[Tuple[str, int]]: samples of a form (path_to_sample, class)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  extra_repr(self) -> str\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |      Parameterizes a generic class.\n",
      " |      \n",
      " |      At least, parameterizing a generic class is the *main* thing this method\n",
      " |      does. For example, for some generic class `Foo`, this is called when we\n",
      " |      do `Foo[int]` - there, with `cls=Foo` and `params=int`.\n",
      " |      \n",
      " |      However, note that this method is also called when defining generic\n",
      " |      classes in the first place with `class Foo(Generic[T]): ...`.\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torchvision.datasets.ImageFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b4e4de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader\n",
    "train_path= r\"C:\\Users\\caren\\OneDrive\\Desktop\\customised dataset 25000 pictures\\archive\\seg_train\\seg_train\"\n",
    "test_path= r\"C:\\Users\\caren\\OneDrive\\Desktop\\customised dataset 25000 pictures\\archive\\seg_test\\seg_test\"\n",
    "train_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "test_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
    "    batch_size=32, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58cb3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categories\n",
    "root=pathlib.Path(train_path)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82168577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e066bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=6):\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        #Output size after convolution filter\n",
    "        #((w-f+2P)/s) +1\n",
    "        \n",
    "        #Input shape= (256,3,150,150)\n",
    "        \n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,12,150,150)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        #Shape= (256,12,150,150)\n",
    "        self.relu1=nn.ReLU()\n",
    "        #Shape= (256,12,150,150)\n",
    "        \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        #Reduce the image size be factor 2\n",
    "        #Shape= (256,12,75,75)\n",
    "        \n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,20,75,75)\n",
    "        self.relu2=nn.ReLU()\n",
    "        #Shape= (256,20,75,75)\n",
    "        \n",
    "         \n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,32,75,75)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        #Shape= (256,32,75,75)\n",
    "        self.relu3=nn.ReLU()\n",
    "        #Shape= (256,32,75,75)\n",
    "        \n",
    "        \n",
    "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Feed forwad function\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "            \n",
    "        output=self.pool(output)\n",
    "            \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "            \n",
    "            \n",
    "            #Above output will be in matrix form, with shape (256,32,75,75)\n",
    "            \n",
    "        output=output.view(-1,32*75*75)\n",
    "            \n",
    "            \n",
    "        output=self.fc(output)\n",
    "            \n",
    "        return output   \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8969f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ConvNet(num_classes=6).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "675c18e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optmizer and loss function\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "loss_function=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c65bdbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "410649a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the size of training and testing images\n",
    "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c64386c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14034 3000\n"
     ]
    }
   ],
   "source": [
    "print(train_count,test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27550f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: tensor(5.9605) Train Accuracy: 0.5907795354139946 Test Accuracy: 0.6613333333333333\n",
      "Epoch: 1 Train Loss: tensor(1.8766) Train Accuracy: 0.7069972922901525 Test Accuracy: 0.7046666666666667\n",
      "Epoch: 2 Train Loss: tensor(0.6331) Train Accuracy: 0.8103890551517743 Test Accuracy: 0.6573333333333333\n",
      "Epoch: 3 Train Loss: tensor(0.4854) Train Accuracy: 0.8487245261507766 Test Accuracy: 0.7213333333333334\n",
      "Epoch: 4 Train Loss: tensor(0.3627) Train Accuracy: 0.8870599971497791 Test Accuracy: 0.744\n",
      "Epoch: 5 Train Loss: tensor(0.2615) Train Accuracy: 0.9164172723386063 Test Accuracy: 0.709\n",
      "Epoch: 6 Train Loss: tensor(0.2193) Train Accuracy: 0.9326635314236853 Test Accuracy: 0.7626666666666667\n",
      "Epoch: 7 Train Loss: tensor(0.2351) Train Accuracy: 0.9295282884423542 Test Accuracy: 0.7296666666666667\n",
      "Epoch: 8 Train Loss: tensor(0.1733) Train Accuracy: 0.9487672794641585 Test Accuracy: 0.7373333333333333\n",
      "Epoch: 9 Train Loss: tensor(0.1375) Train Accuracy: 0.9583867749750605 Test Accuracy: 0.7353333333333333\n"
     ]
    }
   ],
   "source": [
    "#Model training and saving best model\n",
    "\n",
    "best_accuracy=0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Evaluation and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "    \n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        train_loss+= loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    train_accuracy=train_accuracy/train_count\n",
    "    train_loss=train_loss/train_count\n",
    "    \n",
    "    \n",
    "    # Evaluation on testing dataset\n",
    "    model.eval()\n",
    "    \n",
    "    test_accuracy=0.0\n",
    "    for i, (images,labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            outputs=model(images)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "    \n",
    "    test_accuracy=test_accuracy/test_count\n",
    "    \n",
    "    \n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
    "    \n",
    "    #Save the best model\n",
    "    if test_accuracy>best_accuracy:\n",
    "        torch.save(model.state_dict(),'best_checkpointmodel.pth')\n",
    "        best_accuracy=test_accuracy\n",
    "    #plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ff2d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b234b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a0be0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
